{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../hypothesis_generation')\n",
    "\n",
    "\n",
    "from PIL import Image as PImage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from torchvision.utils import make_grid\n",
    "import torch\n",
    "from hypothesis_generation.prefix_postfix import PrefixPostfix\n",
    "from hypothesis_generator import GrammarExpander\n",
    "from reduce_and_process_hypotheses import MetaDatasetExample\n",
    "from reduce_and_process_hypotheses import HypothesisEval\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_file = \"/private/home/ramav/code/ad_hoc_categories/concept_data/clevr_typed_fol_properties.json\"\n",
    "grammar_expander = (\"/private/home/ramav/code/ad_hoc_categories\"\n",
    "                    \"/concept_data/temp_data/v2_typed_simple_fol_clevr_typed_fol_properties.pkl\")\n",
    "program_converter = PrefixPostfix(\n",
    "    properties_file, grammar_expander_file=grammar_expander\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_example(query_and_support, data_idx, split_name=\"train\", nrows=5, filter_or=True,\n",
    "                      nimages_per_row=5):\n",
    "    # TODO(ramav): nimages per row is not something that should be left as a free variable to supply.        \n",
    "    _TOTAL_NEGATIVES=20\n",
    "        \n",
    "    hypothesis = query_and_support[split_name].hypothesis\n",
    "    positive_images_per_row = 5\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 20))\n",
    "    for idx, image_path in enumerate(query_and_support[split_name].image_paths):\n",
    "        ax = plt.subplot(1, positive_images_per_row, idx + 1)\n",
    "        img = mpimg.imread(image_path)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        if idx == 0:\n",
    "            ax.set_title(\"%d] <Original Query>: %s\" % (data_idx, program_converter.postfix_to_prefix(hypothesis)))\n",
    "    \n",
    "    \n",
    "    if filter_or == True:\n",
    "        idx_to_print = [idx for idx, x in enumerate(\n",
    "            query_and_support[split_name].alternate_hypothesis_str) if \" or \" not in x]\n",
    "        \n",
    "    else:\n",
    "        idx_to_print = range(len(query_and_support[split_name].alternate_hypothesis_str))\n",
    "        \n",
    "    if len(query_and_support[split_name].alternate_hypothesis_str) * _TOTAL_NEGATIVES !=  len(\n",
    "        query_and_support[split_name].image_paths_negative):\n",
    "        print(\"%d ratio\" % (len(query_and_support[split_name].image_paths_negative)\n",
    "                           / len(query_and_support[split_name].alternate_hypothesis_str)))\n",
    "        raise ValueError\n",
    "        \n",
    "    printed_idx_count = 0\n",
    "    nrows = len(idx_to_print)\n",
    "    fig = plt.figure(figsize=(10, 4 + 2 * nrows))    \n",
    "\n",
    "    \n",
    "    for idx, image_path in enumerate(query_and_support[split_name].image_paths_negative):\n",
    "        if (int(idx/_TOTAL_NEGATIVES) not in idx_to_print) or (idx % _TOTAL_NEGATIVES >= nimages_per_row):\n",
    "            continue\n",
    "            \n",
    "        ax = plt.subplot(nrows, nimages_per_row, printed_idx_count + 1)\n",
    "        img = mpimg.imread(image_path)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        if printed_idx_count % nimages_per_row == 0:\n",
    "            ax.set_title(\"%d] <Alternate>: %s\" % (data_idx, program_converter.postfix_to_prefix(\n",
    "                    query_and_support[split_name].alternate_hypothesis_str[int(idx/_TOTAL_NEGATIVES)])))\n",
    "            \n",
    "        printed_idx_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_json = (\"${CURI_DATA_PATH}/\"\n",
    "                \"hypotheses/v2_typed_simple_fol_depth_6_trials_2000000_ban_1_max_scene_id_200/\"\n",
    "                \"comp_sampling_log_linear_test_threshold_0.10_pos_im_5_neg_im_20_train_examples_\"\n",
    "                \"500000_neg_type_alternate_hypotheses_alternate_hypo_1_random_seed_42.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_json, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    dataset = dataset[\"meta_dataset\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Results ###\n",
    "\n",
    "NOTE: Only showing alternate hypotheses for which there is no \"or\" clause, so that we are able to look at and focus on that subset. Location origin (0, 0) is at the top left corner, and the image is the bottom right quadrant.\n",
    "\n",
    "#### List of properties present in the dataset ####\n",
    "       \n",
    "\"COUNTS\": [1, 2, 3],\n",
    "\n",
    "\"COLOR\": [\"gray\",\n",
    "        \"red\",\n",
    "        \"blue\",\n",
    "        \"green\",\n",
    "        \"brown\",\n",
    "        \"purple\",\n",
    "        \"cyan\",\n",
    "        \"yellow\"]\n",
    "        \n",
    "\"SHAPE\": \n",
    "    [\n",
    "        \"cube\",\n",
    "        \"sphere\",\n",
    "        \"cylinder\"\n",
    "    ],\n",
    "    \n",
    "\"MATERIAL\": \n",
    "    [\n",
    "        \"rubber\",\n",
    "        \"metal\"\n",
    "    ],\n",
    "    \n",
    "\"SIZE\":\n",
    "    [\n",
    "        \"large\",\n",
    "        \"small\"\n",
    "    ],\n",
    "    \n",
    "\"LOCX\":\n",
    "    [\n",
    "        \"1\",\n",
    "        \"2\",\n",
    "        \"3\",\n",
    "        \"4\",\n",
    "        \"5\",\n",
    "        \"6\",\n",
    "        \"7\",\n",
    "        \"8\"\n",
    "    ],\n",
    "\"LOCY\":\n",
    "    [\n",
    "        \"1\",\n",
    "        \"2\",\n",
    "        \"3\",\n",
    "        \"4\",\n",
    "        \"5\",\n",
    "        \"6\",\n",
    "        \"7\",\n",
    "        \"8\"\n",
    "    ],\n",
    "    \n",
    "#### Format ####\n",
    "There is example number < original query> followed by images for that concept, and then example number <alternate> followed by alternate images for the other concepts which explain the images corresponding to the <original query>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MetaDatasetExample' object has no attribute 'image_paths_positive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-573e02f2bce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mthis_idx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvisualize_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"support\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-d74558ec430d>\u001b[0m in \u001b[0;36mvisualize_example\u001b[0;34m(query_and_support, data_idx, split_name, nrows, filter_or, nimages_per_row)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_and_support\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_images_per_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MetaDatasetExample' object has no attribute 'image_paths_positive'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for this_idx, datum in enumerate(dataset):\n",
    "    if this_idx > 10:\n",
    "        break\n",
    "    visualize_example(datum, this_idx, \"support\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
